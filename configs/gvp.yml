experiment:
  name: gvp_test
  results_dir: sweep_runs/single_runs

wandb:
  init_kwargs:
    mode: online # options: online, offline, disabled
    project: ligdiff_cluster
    group: 
  watch_model: False
  watch_kwargs:
    log: # (str) One of "gradients", "parameters", "all", or None
    log_freq: 100 # (int) log gradients and parameters every N batches

dataset:
  location: 'data/bindingmoad_mini_ip/'
  rec_elements: ['C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'B'] # ['C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'Mg', 'Mn', 'Zn', 'Ca', 'Fe', 'B']
  lig_elements: ['C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'B']
  remove_hydrogen: True
  min_ligand_atoms: 8 # minimum number of atoms in a ligand, skip all smaller ligands in the dataset when processing
  pocket_edge_algorithm: 'bruteforce-blas'
  lig_box_padding: 8 # angstroms
  pocket_cutoff: 8 # angstroms
  receptor_k: 8
  dataset_size: # used only for debugging
  use_boltzmann_ot: False
  max_fake_atom_frac: 0.0
  interface_distance_threshold: 5
  interface_exclusion_threshold: 2
  
  
graph:
  n_keypoints: 20
  graph_cutoffs: {'rr': 3.5, 'rk': 100, 'kk': 8, 'kl': 8, 'll': 6} # i suppose rk isn'y really necessary because we know all r's are connected to all k's...unless...they are not

rec_encoder:
  n_convs: 4
  hidden_n_node_feat: 256 
  out_n_node_feat: 256
  use_tanh: True
  coords_range: 10
  kp_feat_scale: 1.0
  message_norm: 0
  k_closest: 0
  kp_rad: 5
  no_cg: False
  fix_pos: True
  use_sameres_feat: True
  n_kk_convs: 0
  n_kk_heads: 4
  norm: True

rec_encoder_gvp:
  out_scalar_size: 128
  vector_size: 12
  n_rr_convs: 2
  n_rk_convs: 2
  message_norm: 'mean'
  use_sameres_feat: False 
  kp_rad: 0 
  k_closest: 5
  dropout: 0.2
  n_message_gvps: 3 # the number of GVPs to chain together for the message function
  n_update_gvps: 2 # the number of GVPs to chain together for the update function

diffusion:
  n_timesteps: 1000
  precision: 1.0e-5
  lig_feat_norm_constant: 1
  rl_dist_threshold: 0
  architecture: 'gvp' # which GNN architecture to use. can be gvp or egnn

dynamics:
  n_layers: 6
  hidden_nf: 256
  use_tanh: True # whether to use tanh activation for coordinate updates
  message_norm: 0
  update_kp_feat: False
  norm: True
  ll_k: 0
  kl_k: 5

dynamics_gvp:
  vector_size: 12
  n_convs: 2
  n_hidden_scalars: 128
  update_kp: True
  message_norm: 'mean'
  dropout: 0.2
  ll_k: 0
  kl_k: 5
  n_message_gvps: 3 # the number of GVPs to chain together for the message function
  n_update_gvps: 2 # the number of GVPs to chain together for the update function
  n_noise_gvps: 4 # the number of GVPs to chain together for the noise prediction block

rec_encoder_loss:
  loss_type: 'geom' # can be optimal_transport, gaussian_repulsion, hinge, geom, or none
  use_interface_points: True # must be True for geomloss
  geomloss_kwargs:
    geomloss_type: 'sinkhorn' # can be sinkhorn, hausdorff, energy, gaussian, laplacian
    p: 2
    blur: 0.05
    reach: None
    diameter: None
    scaling: 0.5
    truncate: None
    cost: None
    debias: True


training:
  rec_encoder_loss_weight: 0.1
  rl_hinge_loss_weight: 0
  learning_rate: 1.0e-4
  weight_decay: 1.0e-12
  clip_grad: True
  clip_value: 1.5
  epochs: 800
  batch_size: 64
  test_interval: 1 # measured in epochs
  train_metrics_interval: 0.5 # epochs
  save_interval: 50 # epoch
  sample_interval: 30 # number of epochs between sampling/testing molecules
  test_epochs: 1 # number of epochs to run when evaluating on the test set
  num_workers: 4
  scheduler:
    warmup_length: 1
    rec_enc_weight_decay_midpoint: 0
    rec_enc_weight_decay_scale: 0.25
    restart_interval: 0
    restart_type: 'cosine' # can be either linear or cosine


sampling_config:
  n_receptors: 12
  n_replicates: 10
  rec_enc_batch_size: 128
  diff_batch_size: 128