experiment:
  name: baseline
  results_dir: runs/

wandb:
  init_kwargs:
    mode: disabled # options: online, offline, disabled
    project: ligdiff
    group: 
  watch_model: False
  watch_kwargs:
    log: # (str) One of "gradients", "parameters", "all", or None
    log_freq: 100 # (int) log gradients and parameters every N batches

dataset:
  # TODO: many of these arguments were developed for the crossdocked dataset but are completely irrelevant for the bindingmoad dataset. Need to clean this up.
  location: 'data/bindingmoad_dev/'
  rec_elements: ['C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'B'] # ['C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'Mg', 'Mn', 'Zn', 'Ca', 'Fe', 'B']
  lig_elements: ['C', 'N', 'O', 'S', 'P', 'F', 'Cl', 'Br', 'I', 'B']
  remove_hydrogen: True
  min_ligand_atoms: 8 # minimum number of atoms in a ligand, skip all smaller ligands in the dataset when processing
  pocket_edge_algorithm: 'bruteforce-blas'
  lig_box_padding: 8 # angstroms
  pocket_cutoff: 8 # angstroms
  receptor_k: 8
  dataset_size: 15 # used only for debugging
  use_boltzmann_ot: False
  max_fake_atom_frac: 0.0
  interface_distance_threshold: 5
  interface_exclusion_threshold: 2
  
  
graph:
  n_keypoints: 20
  graph_cutoffs: {'rr': 3.5, 'rk': 100, 'kk': 8, 'kl': 8, 'll': 9}

rec_encoder:
  n_convs: 4
  hidden_n_node_feat: 256 
  out_n_node_feat: 256
  use_tanh: True
  coords_range: 10
  kp_feat_scale: 1.0
  message_norm: 0
  k_closest: 0
  kp_rad: 5
  no_cg: False
  fix_pos: True
  use_sameres_feat: True
  n_kk_convs: 0
  n_kk_heads: 4
  norm: True

rec_encoder_gvp:
  out_scalar_size: 128
  vector_size: 16
  n_rr_convs: 4
  n_rk_convs: 2
  message_norm: 'mean'
  use_sameres_feat: False 
  kp_rad: 0 
  k_closest: 10
  dropout: 0.1
  n_message_gvps: 3 # the number of GVPs to chain together for the message function
  n_update_gvps: 2 # the number of GVPs to chain together for the update function

diffusion:
  n_timesteps: 1000
  precision: 1.0e-5
  lig_feat_norm_constant: 1
  rl_dist_threshold: 0
  architecture: 'egnn' # which GNN architecture to use. can be gvp or egnn
  rec_encoder_type: 'fixed' # can be learned or fixed

dynamics:
  n_layers: 6
  hidden_nf: 256
  use_tanh: True # whether to use tanh activation for coordinate updates
  message_norm: 0
  update_kp_feat: False
  norm: True
  ll_k: 0
  kl_k: 5

dynamics_gvp:
  vector_size: 16
  n_convs: 2
  n_hidden_scalars: 128
  update_kp: True
  message_norm: 'mean'
  dropout: 0.1
  ll_k: 0
  kl_k: 5
  n_message_gvps: 3 # the number of GVPs to chain together for the message function
  n_update_gvps: 2 # the number of GVPs to chain together for the update function
  n_noise_gvps: 4 # the number of GVPs to chain together for the noise prediction block

rec_encoder_loss:
  loss_type: 'optimal_transport' # can be optimal_transport, gaussian_repulsion, hinge, or none
  use_interface_points: False

training:
  rec_encoder_loss_weight: 0.1
  rl_hinge_loss_weight: 0
  learning_rate: 1.0e-4
  weight_decay: 1.0e-12
  clip_grad: True
  clip_value: 1.5
  epochs: 3
  batch_size: 32
  test_interval: 100 # measured in epochs
  train_metrics_interval: 0.1 # epochs
  save_interval: 100 # epoch
  sample_interval: 1 # number of epochs between sampling/testing molecules
  test_epochs: 1 # number of epochs to run when evaluating on the test set
  num_workers: 1
  scheduler:
    warmup_length: 1
    rec_enc_weight_decay_midpoint: 0
    rec_enc_weight_decay_scale: 0.25
    restart_interval: 0
    restart_type: 'cosine' # can be either linear or cosine


sampling_config:
  n_receptors: 1
  n_replicates: 10
  rec_enc_batch_size: 128
  diff_batch_size: 128